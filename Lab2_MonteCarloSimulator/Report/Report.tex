\documentclass{report}
\usepackage[utf8]{inputenc}   % Encoding support
\usepackage{graphicx}         % To include images
\usepackage{listings}         % For code formatting
\usepackage{xcolor}           % To add colors
\usepackage{hyperref}         % For clickable links and references
\usepackage{amsmath, amssymb,amsthm} %For math
\usepackage{comment}
\usepackage{float}
\usepackage{minted}


\title{Report II}
\author{Kevin Deshayes}
\date{\2024-10-14}

\begin{document}

% ----- Title Page -----
\begin{titlepage}
    \centering
    {\huge\bfseries Report on Lab 2 \\[1cm]}  % Title
    \textbf{Author:} Kevin Deshayes\\[0.5cm]  % Author Name
    \textbf{Email:} kede23@student.bth.se\\[0.5cm]  % Email
    \textbf{Course Name:} Mathematical Statistics \\[0.5cm]  % Course Name
    \textbf{Course Code:} MS1403\\[1.5cm]  % Course Code
    \includegraphics[width=0.6\textwidth]{Images/BTH_logo_gray} % Placeholder image
    \vfill
    \textbf{Date:} October 14, 2024  % Manually add the date
    \vspace{2cm}
\end{titlepage}

% ----- Table of Contents -----
\tableofcontents
\newpage
% ----- Code Example -----
\section{R code}\label{sec:r-code}
\input{r-code}

\section{Results}\label{sec:results}
\begin{table}[h]
    \centering
    \begin{tabular}{| c | c | c | c | c | c | c |}
        \hline
        $n$ & Method     & Mean        & Bias         & MSE                     & Skewness    & Kurtosis    \\
        \hline
        10  & Numerical  & 4.905042000 & -0.094957570 & 0.009016940             & 0.240844800 & 3.216145000 \\
        10  & Analytical & 4.905042000 & -0.094957740 & 0.009016973             & 0.240844800 & 3.216145000 \\
        \hline
        20  & Numerical  & 4.950229000 & -0.049771060 & 0.002477158             & 0.124840100 & 3.030776000 \\
        20  & Analytical & 4.950229000 & -0.049771230 & 0.002477175             & 0.124840100 & 3.030776000 \\
        \hline
        50  & Numerical  & 4.984634000 & -0.015365770 & 0.000236106             & 0.061915120 & 3.024987000 \\
        50  & Analytical & 4.984634000 & -0.015365940 & 0.000236112             & 0.061915110 & 3.024987000 \\
        \hline
        90  & Numerical  & 5.007175000 & 0.007175166  & $5.1483 \times 10^{-5}$ & 0.058607470 & 3.049959000 \\
        90  & Analytical & 5.007175000 & 0.007175000  & $5.1481 \times 10^{-5}$ & 0.058607470 & 3.049959000 \\
        \hline
        140 & Numerical  & 4.995738000 & -0.004261530 & $1.8161 \times 10^{-5}$ & 0.085037030 & 3.152488000 \\
        140 & Analytical & 4.995738000 & -0.004261697 & $1.8162 \times 10^{-5}$ & 0.085037020 & 3.152488000 \\
        \hline
    \end{tabular}
    \caption{Comparison of Numerical and Analytical Methods for different $n$ after 1000 repetitions}\label{tab:table}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{Images/EstimationCompreSeeded}
    \caption{Comparison on estimations}
    \label{fig:Estimations}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{Images/bell_curve_plot}
    \caption{Bell curves for numerical and analytical estimators, compared to the normal distribution.}
    \label{fig:Estimation-curves}
\end{figure}



% ----- Data Analysis -----
\section{Analysis}\label{sec:analysis}

\subsection{Testing Environment Parameters}\label{subsec:testing-environment-parameters}
For each sample size, 1000 repetitions were conducted, with \(\mu = 5\) being the true value for the simulations.


\subsection{Observations}\label{subsec:observations}
Both estimations generally follow the Law of Large Numbers, where the bias decreases as the sample size increases.
There is a slight difference between the two estimators at \(n = 50\) and \(n = 140\).
We also observe excess kurtosis close to 3 for all sample sizes, with values approaching 3 as the sample size increases.


\subsection{Discussion}\label{subsec:discussion}
The observed skewness and kurtosis are as expected, with kurtosis near 3, which is typical for the Bernoulli distribution.
As the sample size increases, the estimations become more similar to a normal distribution due to the Central Limit Theorem.
The higher the sample size, the closer the kurtosis gets to 3, indicating convergence towards normality.

Both estimators follow the Law of Large Numbers, showing a general decrease in bias.
However, at \(n = 140\), there is an unexpected increase in bias, which may be due to the randomness in the Monte Carlo simulation, where random numbers generated by the inverse function cause fluctuations.
Despite this, the overall trend supports the Law of Large Numbers, where bias decreases asymptotically as \(N\) approaches infinity, though it does so asymmetrically, leading to spikes and fluctuations.

There is a minor discrepancy between the estimators at \(n = 50\) and \(n = 140\), but this difference, occurring at the eighth decimal place, is negligible in the context of this experiment.
The small difference can be attributed to the nature of the methods used: the iterative algorithm behaves slightly differently from the algebraic estimation in the analytical method.
However, the difference in results between the numerical and analytical approaches is minimal.

\subsection{Conclusions}\label{subsec:conclusions}
\begin{itemize}
    \item Both estimators become more accurate as the sample size increases, following the Law of Large Numbers (LLN).
    \item The distribution assumes a normal distribution as the sample size increases, consistent with the Central Limit Theorem (CLT).
    \item Although the two estimators use different methods, their results are very similar, and the differences are negligible.
\end{itemize}

\end{document}
